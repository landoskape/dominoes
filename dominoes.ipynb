{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6d4d84df-c50a-4eb1-88b3-3ba6b1ef7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some ideas just for curiosity:\n",
    "# - could train an RL model to predict what dominoes are in other agents hands based on what has been played, their line, and what is available...\n",
    "# - for hand-crafted networks, I wonder if graph theory methods can speed up the line-value estimation methods..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d743f019-bcc5-4c13-8aef-98e737e0747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "from copy import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import dominoesGameplay as dg\n",
    "import dominoesAgents as da\n",
    "import dominoesNetworks as dn\n",
    "import dominoesFunctions as df\n",
    "import fileManagement as fm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "48c901ba-4294-4ff4-8d74-ae540752816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific Updates to Value Agents --\n",
    "# - I don't think I need to estimate pre/post states every play. This will save so much computation time, and may even be easier for the agents to learn. \n",
    "# - !! It seems like I do need to estimate pre/post states every play. However, I think there's an alternative solution:\n",
    "#         - instead of measuring TD error between the pre & post state, I can measure TD error between the pre-state and the next agent turn's pre-state.\n",
    "#         - this way, the agent will be able to build longer-term connections, but will still only estimate value once per round of turns...\n",
    "\n",
    "# Blog Post Planning: \n",
    "# 1. Creating a system that plays dominoes\n",
    "# 2. Hand-crafted agents that play with specific rules\n",
    "# 3. Finding a way to represent the game-state in a way that can be fed to a neural network\n",
    "#    3.1 -- Simple networks can't learn how to do addition and biased subtraction...?\n",
    "# 4. Adding information to the game-state about possible line sequences for the network to use more information in deciding how to play\n",
    "#    4.1 -- comparing performance of the lineValueNetwork where it is trained against bad agents or good agents\n",
    "#    4.2 -- comparing performance of the lineValueNetwork when it uses pre-poststate updates on every turn, only it's own turn, or only on it's own turn but before/after all other agents have had their turn...\n",
    "# 5. Building a neural network that can outperform the line value networks without hand-crafted information (e.g. a Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef58a0-7c56-44ed-a40a-5cfd94533afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▊                                              | 43/100 [08:17<10:53, 11.47s/it]"
     ]
    }
   ],
   "source": [
    "# initialize game, and create agents\n",
    "# train lineValue agent against greedy agents (which it can learn to beat easily)\n",
    "numPlayers = 4\n",
    "highestDominoe = 9\n",
    "game = dg.dominoeGame(highestDominoe, numPlayers=numPlayers, shuffleAgents=False, agents=(da.lineValueAgent, da.stupidAgent, da.stupidAgent, da.stupidAgent), device=device)\n",
    "game.getAgent(0).setLearning(True)\n",
    "\n",
    "# run training rounds\n",
    "trainingGames = 100\n",
    "trainingRounds = 50\n",
    "trainingWinnerCount = np.zeros(numPlayers)\n",
    "trainingScoreTally = np.zeros((trainingGames,numPlayers))\n",
    "for gameIdx in tqdm(range(trainingGames)):\n",
    "    game.playGame(rounds=trainingRounds)\n",
    "    trainingWinnerCount[game.currentWinner] += 1\n",
    "    trainingScoreTally[gameIdx] += game.currentScore\n",
    "\n",
    "# measure performance\n",
    "game.getAgent(0).setLearning(False)\n",
    "performanceGames = 10\n",
    "performanceRounds = 50\n",
    "performanceWinnerCount = np.zeros(numPlayers)\n",
    "performanceScoreTally = np.zeros(numPlayers)\n",
    "for _ in tqdm(range(performanceGames)):\n",
    "    game.playGame(rounds=performanceRounds)\n",
    "    performanceWinnerCount[game.currentWinner] += 1 \n",
    "    performanceScoreTally += game.currentScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d02418-8f3b-4140-8af8-4cc47a7629c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report results of training lineValueAgent against greedyAgents\n",
    "print(f\"Games won: {performanceWinnerCount}\")\n",
    "print(f\"Expected score per hand: {performanceScoreTally / performanceGames / performanceRounds}\")\n",
    "c = ['r','g','b','k']\n",
    "for i in range(4):\n",
    "    plt.plot(range(trainingGames), trainingScoreTally[:,i]/trainingRounds, c=c[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec0e78f5-a199-45ad-a414-875e3697a109",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# save intermediary agent: \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m game\u001b[38;5;241m.\u001b[39mgetAgent(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msaveAgentParameters(fm\u001b[38;5;241m.\u001b[39msavePath())\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\dominoes\\dominoesAgents.py:468\u001b[0m, in \u001b[0;36mvalueAgent.saveAgentParameters\u001b[1;34m(self, path, description)\u001b[0m\n\u001b[0;32m    466\u001b[0m agentParameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magentParameters()\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m description:\n\u001b[1;32m--> 468\u001b[0m     modelDescription \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescribe this model briefly: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m     modelDescription \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlineValueNetwork parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dominoes\\Lib\\site-packages\\ipykernel\\kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1206\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1207\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dominoes\\Lib\\site-packages\\ipykernel\\kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Describe this model briefly:  xx\n"
     ]
    }
   ],
   "source": [
    "# save intermediary agent: \n",
    "# game.getAgent(0).saveAgentParameters(fm.savePath())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd03aec9-d354-42d8-afa9-9cfdd82a2d87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\andrew\\\\Documents\\\\GitHub\\\\dominoes\\\\savedNetworks\\\\lineValueAgentParameters_230813_0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m game \u001b[38;5;241m=\u001b[39m dg\u001b[38;5;241m.\u001b[39mdominoeGame(highestDominoe, numPlayers\u001b[38;5;241m=\u001b[39mnumPlayers, agents\u001b[38;5;241m=\u001b[39m(da\u001b[38;5;241m.\u001b[39mlineValueAgentSmall, da\u001b[38;5;241m.\u001b[39mbestLineAgent, da\u001b[38;5;241m.\u001b[39mbestLineAgent, da\u001b[38;5;241m.\u001b[39mbestLineAgent), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      8\u001b[0m fileName \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlineValueAgentParameters_230813_0.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 9\u001b[0m game\u001b[38;5;241m.\u001b[39mgetAgent(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mloadAgentParameters(fm\u001b[38;5;241m.\u001b[39msavePath() \u001b[38;5;241m/\u001b[39m fileName)\n\u001b[0;32m     10\u001b[0m game\u001b[38;5;241m.\u001b[39mgetAgent(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msetLearning(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# run training rounds\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\dominoes\\dominoesAgents.py:484\u001b[0m, in \u001b[0;36mvalueAgent.loadAgentParameters\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadAgentParameters\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[1;32m--> 484\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path,allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    485\u001b[0m     unmutableAttributes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumPlayers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighestDominoe\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdominoes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumDominoes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m uatt \u001b[38;5;129;01min\u001b[39;00m unmutableAttributes:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dominoes\\Lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28mopen\u001b[39m(os_fspath(file), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\andrew\\\\Documents\\\\GitHub\\\\dominoes\\\\savedNetworks\\\\lineValueAgentParameters_230813_0.npy'"
     ]
    }
   ],
   "source": [
    "# initialize new game\n",
    "# keep lineValueAgent (load previously learned parameters from playing against greedyAgents), and have it play against bestLineAgents\n",
    "\n",
    "numPlayers = 4\n",
    "highestDominoe = 9\n",
    "game = dg.dominoeGame(highestDominoe, numPlayers=numPlayers, agents=(da.lineValueAgentSmall, da.bestLineAgent, da.bestLineAgent, da.bestLineAgent), device=device)\n",
    "\n",
    "fileName = 'lineValueAgentParameters_230813_0.npy'\n",
    "game.getAgent(0).loadAgentParameters(fm.savePath() / fileName)\n",
    "game.getAgent(0).setLearning(True)\n",
    "\n",
    "# run training rounds\n",
    "trainingGames = 500\n",
    "trainingRounds = 50\n",
    "trainingWinnerCount = np.zeros(numPlayers)\n",
    "trainingScoreTally = np.zeros((trainingGames,numPlayers))\n",
    "for gameIdx in tqdm(range(trainingGames)):\n",
    "    game.playGame(rounds=trainingRounds)\n",
    "    trainingWinnerCount[game.currentWinner] += 1\n",
    "    trainingScoreTally[gameIdx] += game.currentScore\n",
    "\n",
    "# measure performance\n",
    "game.getAgent(0).setLearning(False)\n",
    "performanceGames = 10\n",
    "performanceRounds = 50\n",
    "performanceWinnerCount = np.zeros(numPlayers)\n",
    "performanceScoreTally = np.zeros(numPlayers)\n",
    "for _ in tqdm(range(performanceGames)):\n",
    "    game.playGame(rounds=performanceRounds)\n",
    "    performanceWinnerCount[game.currentWinner] += 1 \n",
    "    performanceScoreTally += game.currentScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3039d-9b8f-4b99-8282-fdef7f4d56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final agent: \n",
    "game.getAgent(0).saveAgentParameters(fm.savePath())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6cbbcf-72c3-47b9-a560-cb145841a3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# report results of training lineValueAgent against greedyAgents\n",
    "print(f\"Games won: {performanceWinnerCount}\")\n",
    "print(f\"Expected score per hand: {performanceScoreTally / performanceGames / performanceRounds}\")\n",
    "c = ['r','g','b','k']\n",
    "for i in range(4):\n",
    "    plt.plot(range(trainingGames), trainingScoreTally[:,i]/trainingRounds, c=c[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4b708-39d6-46df-a331-7a7fcba814d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbcf04-2df5-4931-a803-7e17d53954bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10223d-0dd9-40f6-be1a-a38d2ce078e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c506ca18-411b-41ad-9e5b-b62a2c12b59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:35<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games won: [9. 3. 2. 1.]\n",
      "Expected score per hand: [ 7.39 12.19 11.14 12.83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize game, and create agents\n",
    "numPlayers = 4\n",
    "highestDominoe = 9\n",
    "\n",
    "agents=(da.lineValueAgent, da.bestLineAgent, da.bestLineAgent, da.bestLineAgent)\n",
    "game = dg.dominoeGame(highestDominoe, numPlayers=numPlayers, agents=agents, defaultAgent=da.dominoeAgent, device=device)\n",
    "\n",
    "fileName = 'lineValueAgentParameters_230802_0.npy'\n",
    "game.getAgent(0).loadAgentParameters(fm.savePath() / fileName)\n",
    "game.getAgent(0).setLearning(False)\n",
    "\n",
    "# measure performance without learning\n",
    "performanceGames = 15\n",
    "performanceRounds = 10\n",
    "performanceWinnerCount = np.zeros(numPlayers)\n",
    "performanceScoreTally = np.zeros(numPlayers)\n",
    "for _ in tqdm(range(performanceGames)):\n",
    "    game.playGame(rounds=performanceRounds)\n",
    "    performanceWinnerCount[game.currentWinner] += 1 \n",
    "    performanceScoreTally += game.currentScore\n",
    "    \n",
    "print(f\"Games won: {performanceWinnerCount}\")\n",
    "print(f\"Expected score per hand: {np.round(performanceScoreTally / performanceGames / performanceRounds * 100)/100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c226d184-d252-4fed-bd43-506985416408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9d1c58c-fec0-4da5-85bd-c782d7363c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Describe this model briefly:  In this model, I pretrained it to learn while playing double agents, then trained it against best line agents. \n"
     ]
    }
   ],
   "source": [
    "# game.getAgent(0).saveAgentParameters(fm.savePath())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c05474-de04-44da-b64d-25f2ead02ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e686b-3005-4cf9-bdb0-a78dedb2050b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd5dd3-2860-42db-9967-60f237b8bac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a2978-054b-4583-be07-59785ffa8942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336eae52-0ca0-4dd1-8d32-5cce89164cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9efffc8-f9b8-40e0-ba45-dfafcd9ecbfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "efa60a9a-4db2-48e8-b39a-9faa9b4cec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 15, 24])\n",
      "torch.Size([10, 15, 24])\n",
      "torch.Size([10, 15, 24])\n"
     ]
    }
   ],
   "source": [
    "from pointerNetwork import AttentionLayer, TransformerBlock\n",
    "\n",
    "batchSize = 10\n",
    "seqLength = 15\n",
    "emb = 24\n",
    "att = AttentionLayer(emb)\n",
    "trans = TransformerBlock(emb, 4, None, seqLength)\n",
    "x = torch.normal(0,1,(batchSize, seqLength, emb))\n",
    "\n",
    "out = att(x)\n",
    "t = trans(x)\n",
    "\n",
    "print(x.shape)\n",
    "print(out.shape)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7be8beff-21d7-454a-9587-9cd068143baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = nn.Linear(24, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "edbaced0-f322-4ffc-808d-0c344ab0a796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 15, 50])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx(out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "142dbb71-ec0a-467d-88f3-bf223f779015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Loss: 0.24199\n",
      "Acc: 100.00% (9000/9000)\n",
      "epoch: 2, Loss: 0.00185\n",
      "Acc: 100.00% (9000/9000)\n",
      "epoch: 4, Loss: 0.00092\n",
      "Acc: 100.00% (9000/9000)\n",
      "----Test result---\n",
      "Acc: 100.00% (1000/1000)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def createData(total_size, input_seq_len):\n",
    "    input, targets = make_seq_data(total_size, input_seq_len)\n",
    "    return input, targets\n",
    "\n",
    "def prepareData(input, targets, total_size):\n",
    "    # Convert to torch tensors\n",
    "    input = to_var(torch.LongTensor(input))     # (N, L)\n",
    "    targets = to_var(torch.LongTensor(targets)) # (N, L)\n",
    "\n",
    "    data_split = (int)(total_size * 0.9)\n",
    "    train_X = input[:data_split]\n",
    "    train_Y = targets[:data_split]\n",
    "    test_X = input[data_split:]\n",
    "    test_Y = targets[data_split:]\n",
    "    \n",
    "    return input, targets, train_X, train_Y, test_X, test_Y\n",
    "\n",
    "# from pointer_network import PointerNetwork\n",
    "def train(model, X, Y, batch_size, n_epochs):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    N = X.size(0)\n",
    "    L = X.size(1)\n",
    "    # M = Y.size(1)\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        # for i in range(len(train_batches))\n",
    "        for i in range(0, N-batch_size, batch_size):\n",
    "            x = X[i:i+batch_size] # (bs, L)\n",
    "            y = Y[i:i+batch_size] # (bs, M)\n",
    "\n",
    "            probs = model(x) # (bs, M, L)\n",
    "            outputs = probs.view(-1, L) # (bs*M, L)\n",
    "            # outputs = probs.view(L, -1).t().contiguous() # (bs*M, L)\n",
    "            y = y.view(-1) # (bs*M)\n",
    "            loss = F.nll_loss(outputs, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            print('epoch: {}, Loss: {:.5f}'.format(epoch, loss.item()))\n",
    "            # for _ in range(2): # random showing results\n",
    "            #     pick = np.random.randint(0, batch_size)\n",
    "            #     probs = probs.contiguous().view(batch_size, M, L).transpose(2, 1) # (bs, L, M)\n",
    "            #     y = y.view(batch_size, M)\n",
    "            #     print(\"predict: \", probs.max(1)[1].data[pick][0], probs.max(1)[1].data[pick][1],\n",
    "            #           \"target  : \", y.data[pick][0], y.data[pick][1])\n",
    "            test(model, X, Y)\n",
    "\n",
    "def test(model, X, Y):\n",
    "    probs = model(X) # (bs, M, L)\n",
    "    _v, indices = torch.max(probs, 2) # (bs, M)\n",
    "    # show test examples\n",
    "    # for i in range(len(indices)):\n",
    "    #     print('-----')\n",
    "    #     print('test', [v for v in X[i].data])\n",
    "    #     print('label', [v for v in Y[i].data])\n",
    "    #     print('pred', [v for v in indices[i].data])\n",
    "    #     if torch.equal(Y[i].data, indices[i].data):\n",
    "    #         print('eq')\n",
    "    #     if i>20: break\n",
    "    correct_count = sum([1 if torch.equal(ind.data, y.data) else 0 for ind, y in zip(indices, Y)])\n",
    "    print('Acc: {:.2f}% ({}/{})'.format(correct_count/len(X)*100, correct_count, len(X)))\n",
    "    \n",
    "def generate_single_seq(length=30, min_len=5, max_len=10):\n",
    "    # https://medium.com/@devnag/pointer-networks-in-tensorflow-with-sample-code-14645063f264\n",
    "    \"\"\" Generates a sequence of numbers of random length and inserts a sub-sequence oh greater numbers at random place\n",
    "    Input:\n",
    "    length: total sequence length\n",
    "    min_len: minimum length of sequence\n",
    "    max_len: maximum length of sequence\n",
    "    Output:\n",
    "    sequence of numbers, index of the start of greater numbers subsequence\"\"\"\n",
    "    seq_before = [(random.randint(1, 5)) for x in range(random.randint(min_len, max_len))]\n",
    "    seq_during = [(random.randint(6, 10)) for x in range(random.randint(min_len, max_len))]\n",
    "    seq_after = [random.randint(1, 5) for x in range(random.randint(min_len, max_len))]\n",
    "    seq = seq_before + seq_during + seq_after\n",
    "    seq = seq + ([0] * (length - len(seq)))\n",
    "    return (seq, len(seq_before), len(seq_before) + len(seq_during)-1)\n",
    "\n",
    "def generate_set_seq(N):\n",
    "    # generate Boundary tasks\n",
    "    \"\"\"Generates a set of N sequences of fixed length\"\"\"\n",
    "    data = []\n",
    "    starts = []\n",
    "    ends = []\n",
    "    for i in range(N):\n",
    "        seq, ind_start, ind_end = generate_single_seq()\n",
    "        data.append(seq)\n",
    "        starts.append(ind_start)\n",
    "        ends.append(ind_end)\n",
    "    return data, starts, ends\n",
    "\n",
    "def make_seq_data(n_samples, seq_len):\n",
    "    # Boundary tasks\n",
    "    data, labels = [], []\n",
    "    for _ in range(n_samples):\n",
    "        input = np.random.permutation(range(seq_len)).tolist()\n",
    "        target = sorted(range(len(input)), key=lambda k: input[k])\n",
    "        data.append(input)\n",
    "        labels.append(target)\n",
    "    return data, labels\n",
    "\n",
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "class PointerNetwork(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, weight_size, answer_seq_len, hidden_size=512, is_GRU=True):\n",
    "        super(PointerNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.answer_seq_len = answer_seq_len\n",
    "        self.weight_size = weight_size\n",
    "        self.emb_size = emb_size\n",
    "        self.is_GRU = is_GRU\n",
    "\n",
    "        self.emb = nn.Embedding(input_size, emb_size)  # embed inputs\n",
    "        if is_GRU:\n",
    "            self.enc = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
    "            self.dec = nn.GRUCell(emb_size, hidden_size) # GRUCell's input is always batch first\n",
    "        else:\n",
    "            self.enc = nn.LSTM(emb_size, hidden_size, batch_first=True)\n",
    "            self.dec = nn.LSTMCell(emb_size, hidden_size) # LSTMCell's input is always batch first\n",
    "\n",
    "        self.W1 = nn.Linear(hidden_size, weight_size, bias=False) # blending encoder\n",
    "        self.W2 = nn.Linear(hidden_size, weight_size, bias=False) # blending decoder\n",
    "        self.vt = nn.Linear(weight_size, 1, bias=False) # scaling sum of enc and dec by v.T\n",
    "\n",
    "    def forward(self, input, printShapes=False):\n",
    "        if printShapes: print(f\"Input shape: {input.shape}\")\n",
    "        batch_size = input.size(0)\n",
    "        input = self.emb(input) # (bs, L, embd_size)\n",
    "        \n",
    "        if printShapes: print(f\"Embedding shape: {input.shape}\")\n",
    "        \n",
    "        # Encoding\n",
    "        encoder_states, hc = self.enc(input) # encoder_state: (bs, L, H)\n",
    "        encoder_states = encoder_states.transpose(1, 0) # (L, bs, H)\n",
    "        \n",
    "        if printShapes: print(f\"Encoder_states shape: {encoder_states.shape}\")\n",
    "        if printShapes: print(f\"hc shape: {hc.shape}\")\n",
    "        \n",
    "        # Decoding states initialization\n",
    "        decoder_input = to_var(torch.zeros(batch_size, self.emb_size)) # (bs, embd_size)\n",
    "        hidden = to_var(torch.zeros([batch_size, self.hidden_size]))   # (bs, h)\n",
    "        cell_state = encoder_states[-1]                                # (bs, h)\n",
    "        \n",
    "        if printShapes: print(f\"decoder_input shape: {decoder_input.shape}\")\n",
    "        if printShapes: print(f\"hidden shape: {hidden.shape}\")\n",
    "        if printShapes: print(f\"cell_state shape: {cell_state.shape}\")\n",
    "        if printShapes: print(f\"\\nNow at decoding layer: \\n\")\n",
    "        probs = []\n",
    "        # Decoding\n",
    "        for i in range(self.answer_seq_len): # range(M)\n",
    "            if self.is_GRU:\n",
    "                hidden = self.dec(decoder_input, hidden) # (bs, h), (bs, h)\n",
    "                if printShapes: print(f\"hidden shape: {hidden.shape}\")\n",
    "            else:\n",
    "                hidden, cell_state = self.dec(decoder_input, (hidden, cell_state)) # (bs, h), (bs, h)\n",
    "                if printShapes: print(f\"hidden shape: {hidden.shape}\")\n",
    "                if printShapes: print(f\"cell_state shape: {cell_state.shape}\")\n",
    "            \n",
    "            # Compute blended representation at each decoder time step\n",
    "            blend1 = self.W1(encoder_states)          # (L, bs, W)\n",
    "            blend2 = self.W2(hidden)                  # (bs, W)\n",
    "            blend_sum = torch.tanh(blend1 + blend2)    # (L, bs, W)\n",
    "            out = self.vt(blend_sum).squeeze()        # (L, bs)\n",
    "            out = F.log_softmax(out.transpose(0, 1).contiguous(), -1) # (bs, L)\n",
    "            probs.append(out)\n",
    "            \n",
    "            if printShapes: print(f\"blend1 shape: {blend1.shape}\")\n",
    "            if printShapes: print(f\"blend2 shape: {blend2.shape}\")\n",
    "            if printShapes: print(f\"blend_sum shape: {blend_sum.shape}\")\n",
    "            if printShapes: print(f\"out shape: {out.shape}\")\n",
    "\n",
    "        probs = torch.stack(probs, dim=1)           # (bs, M, L)\n",
    "\n",
    "        return probs\n",
    "\n",
    "total_size = 10000\n",
    "weight_size = 256\n",
    "input_seq_len = 5\n",
    "emb_size = 256\n",
    "batch_size = 250\n",
    "n_epochs = 5\n",
    "inp_size = input_seq_len\n",
    "\n",
    "input, targets = createData(total_size, input_seq_len)\n",
    "input, targets, train_X, train_Y, test_X, test_Y = prepareData(input, targets, total_size)\n",
    "model = PointerNetwork(inp_size, emb_size, weight_size, input_seq_len)\n",
    "if torch.cuda.is_available(): model.cuda()\n",
    "train(model, train_X, train_Y, batch_size, n_epochs)\n",
    "print('----Test result---')\n",
    "test(model, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad9d87f-6c57-4b59-ab00-de4f8a142f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([8, 5])\n",
      "Embedding shape: torch.Size([8, 5, 256])\n",
      "Encoder_states shape: torch.Size([5, 8, 512])\n",
      "hc shape: torch.Size([1, 8, 512])\n",
      "decoder_input shape: torch.Size([8, 256])\n",
      "hidden shape: torch.Size([8, 512])\n",
      "cell_state shape: torch.Size([8, 512])\n",
      "\n",
      "Now at decoding layer: \n",
      "\n",
      "hidden shape: torch.Size([8, 512])\n",
      "blend1 shape: torch.Size([5, 8, 256])\n",
      "blend2 shape: torch.Size([8, 256])\n",
      "blend_sum shape: torch.Size([5, 8, 256])\n",
      "out shape: torch.Size([8, 5])\n",
      "hidden shape: torch.Size([8, 512])\n",
      "blend1 shape: torch.Size([5, 8, 256])\n",
      "blend2 shape: torch.Size([8, 256])\n",
      "blend_sum shape: torch.Size([5, 8, 256])\n",
      "out shape: torch.Size([8, 5])\n",
      "hidden shape: torch.Size([8, 512])\n",
      "blend1 shape: torch.Size([5, 8, 256])\n",
      "blend2 shape: torch.Size([8, 256])\n",
      "blend_sum shape: torch.Size([5, 8, 256])\n",
      "out shape: torch.Size([8, 5])\n",
      "hidden shape: torch.Size([8, 512])\n",
      "blend1 shape: torch.Size([5, 8, 256])\n",
      "blend2 shape: torch.Size([8, 256])\n",
      "blend_sum shape: torch.Size([5, 8, 256])\n",
      "out shape: torch.Size([8, 5])\n",
      "hidden shape: torch.Size([8, 512])\n",
      "blend1 shape: torch.Size([5, 8, 256])\n",
      "blend2 shape: torch.Size([8, 256])\n",
      "blend_sum shape: torch.Size([5, 8, 256])\n",
      "out shape: torch.Size([8, 5])\n",
      "-----\n",
      "test:  [3 2 0 1 4]\n",
      "label: [2 3 1 0 4]\n",
      "pred:  [2 3 1 0 4]\n",
      "-----\n",
      "test:  [2 1 4 0 3]\n",
      "label: [3 1 0 4 2]\n",
      "pred:  [3 1 0 4 2]\n",
      "-----\n",
      "test:  [0 3 4 2 1]\n",
      "label: [0 4 3 1 2]\n",
      "pred:  [0 4 3 1 2]\n",
      "-----\n",
      "test:  [0 4 2 3 1]\n",
      "label: [0 4 2 3 1]\n",
      "pred:  [0 4 2 3 1]\n",
      "-----\n",
      "test:  [1 4 3 0 2]\n",
      "label: [3 0 4 2 1]\n",
      "pred:  [3 0 4 2 1]\n",
      "-----\n",
      "test:  [1 2 0 4 3]\n",
      "label: [2 0 1 4 3]\n",
      "pred:  [2 0 1 4 3]\n",
      "-----\n",
      "test:  [4 0 3 2 1]\n",
      "label: [1 4 3 2 0]\n",
      "pred:  [1 4 3 2 0]\n",
      "-----\n",
      "test:  [4 3 0 1 2]\n",
      "label: [2 3 4 1 0]\n",
      "pred:  [2 3 4 1 0]\n",
      "Acc: 0.80% (8/1000)\n"
     ]
    }
   ],
   "source": [
    "probs = model.forward(test_X[:8], printShapes=True) # (bs, M, L)\n",
    "_v, indices = torch.max(probs, 2) # (bs, M)\n",
    "# show test examples\n",
    "for i in range(len(indices)):\n",
    "    print('-----')\n",
    "    print(f'test:  {test_X[i].detach().cpu().numpy()}')\n",
    "    print(f'label: {test_Y[i].detach().cpu().numpy()}')\n",
    "    print(f'pred:  {indices[i].detach().cpu().numpy()}')\n",
    "    if i>20: break\n",
    "correct_count = sum([1 if torch.equal(ind.data, y.data) else 0 for ind, y in zip(indices, test_Y)])\n",
    "print('Acc: {:.2f}% ({}/{})'.format(correct_count/len(test_X)*100, correct_count, len(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e39d1-6b61-4437-ac10-9f25702353a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98613f60-4fc1-4ea3-8d1e-00bd7e65a5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d1f529-5ce1-49cd-bc1e-bd3587a1ad6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb88b80-e03f-4fcd-95e6-4ab2b23fc4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ca1e3f-0f69-466d-9d53-16185f3e8b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c90df6a-0207-4b57-af72-7ab1dff07337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940550c-ffcc-465f-baba-bba8f45139b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e35543-4db2-49f0-96fc-d36859b5ffc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15ffd9-eed0-4f39-bb1d-a710d0019cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448cd0a-e7e7-440a-8aad-79033249be9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919df8bb-2db7-49fc-b740-578146182059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e25db2-3138-4f4f-a95e-a29c74c29bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d563a8-cca3-48fa-bc78-212faaaa5515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396bcd2-d6a2-48fa-b730-c035d654322d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cdff3f-d72f-454e-ae0a-5c2d000612a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa51f02-b47d-44c5-947b-80607a4b7775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3cacb-899a-4203-ba9e-58c9ae165fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f732f3-ed54-428f-949b-48ae94b6fb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055259c-d643-4be2-aaee-c768c75e3e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab299726-8d74-4c3d-80fc-fe1f23b71121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec629c8c-8757-4e44-beac-377f8535214a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f67250-5053-44f1-878a-2800904070d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1708b-c730-4896-9e83-97fa5c558414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58281d24-80a9-4ba3-8fe0-bfad9d6d33c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34394ca-afce-4130-86d8-518de762430d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf91de7-6d74-4ea7-bd4c-5957126a02f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ffb2790-9c12-4ed3-a650-a0163e9a3526",
   "metadata": {},
   "source": [
    "## Below this point I'm including some code blocks that make inspection of the gameplay and agent status easy... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ff4c26a2-a5a8-410d-9795-b88680257fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  25  57  20]\n",
      " [130  97 129 123]\n",
      " [136 104 106 135]\n",
      " [118 118 140 107]\n",
      " [ 83 136 124 142]\n",
      " [127 127 113 120]\n",
      " [133 114 120 122]\n",
      " [119 151 134  87]\n",
      " [122 132 116 123]\n",
      " [119 110 133 133]]\n",
      "[1087 1114 1172 1112]\n",
      "The winner is agent: 0 with a score of 1087!\n"
     ]
    }
   ],
   "source": [
    "numPlayers = 4\n",
    "highestDominoe = 9\n",
    "game = dg.dominoeGame(highestDominoe, agents=(da.doubleAgent, da.greedyAgent, None, da.stupidAgent))\n",
    "game.playGame()\n",
    "game.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6f8fa238-52ca-4b98-b287-1a9d283e1c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 9|7 ', ' 7|7 ', ' 7|5 ', ' 5|5 ', ' 5|4 ', ' 4|0 ', ' 0|0 ']\n",
      "[' 9|5 ', ' 5|6 ', ' 6|7 ', ' 7|8 ', ' 8|4 ', ' 4|7 ', ' 7|3 ', ' 3|8 ', ' 8|2 ', ' 2|4 ']\n",
      "[' 9|8 ', ' 8|0 ', ' 0|7 ', ' 7|1 ', ' 1|1 ', ' 1|5 ', ' 5|3 ', ' 3|2 ']\n",
      "[' 9|2 ', ' 2|6 ', ' 6|3 ', ' 3|0 ', ' 0|5 ', ' 5|8 ', ' 8|1 ']\n",
      "[' 9|6 ', ' 6|0 ', ' 0|9 ', ' 9|3 ', ' 3|3 ', ' 3|4 ', ' 4|4 ', ' 4|6 ', ' 6|6 ', ' 6|1 ', ' 1|4 ', ' 4|9 ', ' 9|1 ']\n"
     ]
    }
   ],
   "source": [
    "numPlayers = 4\n",
    "highestDominoe = 9\n",
    "game = dg.dominoeGame(highestDominoe, agents=(da.doubleAgent, da.greedyAgent, None, da.stupidAgent))\n",
    "game.playHand()\n",
    "df.gameSequenceToString(game.dominoes, game.lineSequence, game.linePlayDirection, player=None, playNumber=None) #player=game.linePlayer, playNumber=game.linePlayNumber)\n",
    "df.gameSequenceToString(game.dominoes, game.dummySequence, game.dummyPlayDirection, player=None, playNumber=None) #player=game.linePlayer, playNumber=game.linePlayNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "1d0ae873-32f9-4a21-9724-741e666c36b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line 0: []\n",
      "line 1: []\n",
      "line 2: []\n",
      "line 3: []\n",
      "dummy: []\n",
      "Dominoe: None, Location: None\n"
     ]
    }
   ],
   "source": [
    "# Example of options list for current game (requires game.initializeHand() and game.presentGameState() to be run)\n",
    "lineOptions, dummyOptions = game.agents[0].playOptions()\n",
    "df.printDominoeList(lineOptions, game.agents[0].dominoes, name='line')\n",
    "df.printDominoeList(dummyOptions, game.agents[0].dominoes, name='dummy:')\n",
    "dominoe, location = game.agents[0].selectPlay()\n",
    "print(f\"Dominoe: {dominoe}, Location: {location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "81fa6014-2a23-40f7-9955-d7f4ee1dc486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [1], []]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# game details\n",
    "game.lineSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "969bb5b6-46c8-4c45-acfd-d4dd83f1c3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 1000000/1000000 [24:04<00:00, 692.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4527309322357178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x200c936a130>]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create random game states and then train a network to predict current hand score...\n",
    "def generateRandomHand(dominoes, numDominoes, numPlayers, verboseOutput=False):\n",
    "    numInHands = np.random.randint(numDominoes+1)\n",
    "    idxInHands = np.random.choice(numDominoes,numInHands,replace=False)\n",
    "    handIdx = np.random.randint(0, numPlayers, numInHands)\n",
    "    played = np.full(numDominoes, True)\n",
    "    myHand = np.full(numDominoes, False)\n",
    "    otherHands = np.full(numDominoes, False)\n",
    "    played[idxInHands]=False\n",
    "    myHand[idxInHands[handIdx==0]] = True\n",
    "    otherHands[idxInHands[handIdx>0]] = True\n",
    "    myHandValue = np.sum(dominoes[myHand])\n",
    "    otherHandValue = np.sum(dominoes[otherHands])\n",
    "    if verboseOutput:\n",
    "        return played, myHand, otherHands, myHandValue, otherHandValue\n",
    "    networkInput = (np.concatenate((played, myHand))*1)\n",
    "    networkOutput = np.array([myHandValue, otherHandValue])\n",
    "    # networkInput = np.concatenate((np.sum(dominoes.T * played, axis=0), np.sum(dominoes.T * myHand, axis=0)))\n",
    "    return networkInput, networkOutput\n",
    "\n",
    "# played, myHand, otherHands, myHandValue, otherHandValue = generateRandomHand(dominoes, numDominoes, numPlayers, verboseOutput=True)\n",
    "networkInput, networkOutput = generateRandomHand(dominoes, numDominoes, numPlayers)\n",
    "\n",
    "numPlayers = 3\n",
    "highestDominoe = 9\n",
    "numDominoes = df.numberDominoes(highestDominoe)\n",
    "dominoes = df.listDominoes(highestDominoe)\n",
    "\n",
    "handValueNetwork = dn.handValueNetwork(numPlayers,numDominoes,highestDominoe)\n",
    "handValueNetwork.to(device)\n",
    "\n",
    "numIterations = 1000000\n",
    "target = np.zeros((numIterations, 2))\n",
    "pred = np.zeros((numIterations, 2))\n",
    "storeLoss = np.zeros(numIterations)\n",
    "\n",
    "lossFunction = nn.L1Loss()\n",
    "# optimizer = torch.optim.SGD(handValueNetwork.parameters(), lr=1e-2, momentum=0.5)\n",
    "optimizer = torch.optim.Adadelta(handValueNetwork.parameters())\n",
    "\n",
    "for ii in tqdm(range(numIterations)):\n",
    "    networkInput, networkOutput = generateRandomHand(dominoes, numDominoes, numPlayers)\n",
    "    target[ii] = np.copy(networkOutput)\n",
    "    \n",
    "    networkInput = torch.tensor(networkInput).to(device).float()\n",
    "    networkOutput = torch.tensor(networkOutput).to(device).float()\n",
    "    \n",
    "    output = handValueNetwork(networkInput)\n",
    "    \n",
    "    loss = lossFunction(output, networkOutput)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    storeLoss[ii] = loss.item()\n",
    "    pred[ii] = output.detach().cpu().numpy()\n",
    "    \n",
    "print(np.mean(storeLoss[-100:]))\n",
    "fig,ax = plt.subplots(1,2,figsize=(7,3))\n",
    "ax[0].plot(range(numIterations), storeLoss, linewidth=0.5)\n",
    "ax[1].plot(range(numIterations), pred[:,0]-target[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4ed9f-c61e-4e19-9235-6e2ec58a5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of options list for current game (requires game.initializeHand() and game.presentGameState() to be run)\n",
    "print(f\"Line available: {game.available}, dummy available: {game.dummyAvailable}\")\n",
    "print(f\"Penny-up: {game.cantPlay}, dummy playable: {game.dummyPlayable}\")\n",
    "print(f\"Hand-size: {game.handSize}, manualHandSize: {[len(agent.myHand) for agent in game.agents]}\")\n",
    "print(\"\")\n",
    "game.agents[game.nextPlayer].gameState(game.played, game.available, game.handSize, game.cantPlay, game.didntPlay, game.turnCounter, game.dummyAvailable, game.dummyPlayable)\n",
    "lineOptions, dummyOptions = game.agents[game.nextPlayer].playOptions()\n",
    "df.printDominoeList(lineOptions, game.agents[game.nextPlayer].dominoes, name='line')\n",
    "df.printDominoeList(dummyOptions, game.agents[game.nextPlayer].dominoes, name='dummy:')\n",
    "dominoe, location = game.agents[game.nextPlayer].selectPlay()\n",
    "if dominoe is not None:\n",
    "    print(f\"~{game.agents[game.nextPlayer].agentName}~ agent played dominoe: {dominoe}: {df.dominoesString(game.dominoes[dominoe])} on location: {location}.\")\n",
    "else:\n",
    "    print(f\"~{game.agents[game.nextPlayer].agentName}~ agent could not play!\")\n",
    "game.doTurn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80913481-af53-4d8a-92b8-7916242d3f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
