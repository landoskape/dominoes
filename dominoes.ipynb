{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4d84df-c50a-4eb1-88b3-3ba6b1ef7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple system to operate a dominoes game\n",
    "\n",
    "# -- top level \"API\" for game --\n",
    "# inputs:\n",
    "# 1. number of players\n",
    "# 2. maximum number of dominoes\n",
    "# 3. rule for creating player agent, or preset list of agents\n",
    "# operation:\n",
    "# 1. distribute dominoes to each player randomly\n",
    "# 2. create turn list\n",
    "# 3. query players for their play (evaluate whether the play is valid and accept or reject it)\n",
    "# 4. identify winner, track score, initiate new round until 0/0 is finished\n",
    "\n",
    "# -- agent --\n",
    "# 1. one-hot of dominoes in hand\n",
    "# 2. one-hot of dominoes already played\n",
    "# 3. multi-length vector, one input for each other player, containing: 1) how many dominoes in their hand, 2) whether they have a penny up, 3) how many turns until they play\n",
    "# 4. number of turns until the agent plays\n",
    "# 5. one-hot of dominoes available to play on\n",
    "# 6. dominoe played on last turn? \n",
    "\n",
    "# -- simple agents --\n",
    "# 1. play random dominoe\n",
    "# 2. play highest dominoe\n",
    "# 3. play double-pair dominoe\n",
    "# 4. RL agent...\n",
    "\n",
    "# -- observation agents --\n",
    "# 1. I can train an independent RL model to predict the points at the end of each game from the current game state and run that independently. \n",
    "#    This would work by feeding in the full game state, then having the network predict the value on the next turn, and then learn from the last turn moving backwards (with uncertainty etc.)\n",
    "#    Then, I can teach this observer using games from crystallized agents, and update one agent to see how much better it performs than change. \n",
    "#    Additionally, this agent could maybe be integrated into the gameplay agents? \n",
    "# 2. Could train an RL model to predict what dominoes are in other agents hands based on what has been played, their line, and what is available..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d743f019-bcc5-4c13-8aef-98e737e0747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dominoesGameplay as dg\n",
    "import dominoesAgents as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "06a8e42f-29d5-4a18-830b-550e311a48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numPlayers = 4\n",
    "highestDominoe = 5\n",
    "game = dg.dominoeGame(numPlayers, highestDominoe)\n",
    "game.initializeHand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "916a28ec-76ba-4979-b349-a9c8aff59c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numPlayers, highestDominoe, dominoes, numDominoes, agentIndex\n",
    "\n",
    "numPlayers = 4\n",
    "highestDominoe = 5\n",
    "dominoes = game.dominoes\n",
    "numDominoes = game.numDominoes\n",
    "agentIndex = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "acb6c211-93d0-4643-8283-feb70a4f17e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = da.dominoeAgent(numPlayers, highestDominoe, dominoes, numDominoes, agentIndex)\n",
    "agentS = da.agentStupid(numPlayers, highestDominoe, dominoes, numDominoes, agentIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89057a08-a78f-4cb9-a250-cceafaac7d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
