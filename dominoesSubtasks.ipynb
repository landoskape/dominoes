{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc1fa0d-ae36-46df-aa4e-6c838e35dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is used for developing networks for subtasks of the main one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69ed9ab7-7d09-4a29-9dcb-c76b3d0dc4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from copy import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dominoes import gameplay as dg\n",
    "from dominoes import agents as da\n",
    "from dominoes import functions as df\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import subtasks\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12db2617-cd62-4ad4-9c9a-f83224d9635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sub Task 1: Train a network to predict self-hand value and other hand value based on the tokens in the hand\n",
    "# outputs = subtasks.subTask1()\n",
    "# net, testOutput, testTarget, testLoss, trainingLoss, printResults = outputs\n",
    "# printResults(df.listDominoes(12), trainingLoss, testOutput, testTarget, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1da0b4-c635-4786-a1aa-8111ca4ec73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a21c22-8c73-4b03-9d2b-cbbdb63bcaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37746d0b-c68d-44f2-8a37-724c4c3daf54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pointerNetwork as pn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0cd9b0f-d1b8-473e-96a2-6fd9ac18078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the dataset using a value-value embedding where each value on the dominoe is indicated\n",
    "class dominoeHandDataset(Dataset):\n",
    "    def __init__(self, highestDominoe, minInHand, maxInHand, numSamples=1000):\n",
    "        self.highestDominoe = highestDominoe\n",
    "        self.dominoes = df.listDominoes(highestDominoe)\n",
    "        self.numDominoes = len(self.dominoes)\n",
    "        self.minInHand = np.maximum(minInHand, 1)\n",
    "        self.maxInHand = np.minimum(maxInHand, self.numDominoes)\n",
    "        self.numSamples = numSamples\n",
    "        self.embedDim = 2*(self.highestDominoe+1) + 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        cInHand = np.random.randint(self.minInHand, self.maxInHand+1)\n",
    "        cHand = np.random.choice(self.numDominoes, cInHand, replace=False)\n",
    "        cEmbeddings = self.embed(cHand)\n",
    "        return cEmbeddings\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.numSamples\n",
    "        \n",
    "    def embed(self, hand):\n",
    "        numTokens = len(hand)+1\n",
    "        embeddings = []\n",
    "        for d in hand:\n",
    "            dValues = self.dominoes[d]\n",
    "            firstHalf = [1 if dValues[0] == i else 0 for i in range(self.highestDominoe+1)]\n",
    "            secondHalf = [1 if dValues[1] == i else 0 for i in range(self.highestDominoe+1)]\n",
    "            embeddings.append(firstHalf+secondHalf+[0])\n",
    "        embeddings.append([0]*2*(self.highestDominoe+1)+[1])\n",
    "        return embeddings\n",
    "\n",
    "    def embedFast(self, hand):\n",
    "        numTokens = len(hand)+1\n",
    "        oneHotRowCol = \n",
    "        embeddings = torch.zeros((numTokens,self.embedDim))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "411bb8b0-5311-424a-841f-988fa4ae3ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 5]\n",
      " [1 7]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(colIdx)\n\u001b[0;32m      5\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolIdx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "x = np.array([[0,0],[1,2]])\n",
    "colIdx = x + np.array([0,5])\n",
    "print(colIdx)\n",
    "\n",
    "out = np.zeros((2,10))\n",
    "out[colIdx] = 1\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a58712f-6def-4742-ac15-14062eefbc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dhdata = dominoeHandDataset(9, 3, 10)\n",
    "dhLoader = DataLoader(dataset=dhdata, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd1e3153-4b3a-4558-a418-7501e58caedf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [10] at entry 0 and [5] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdhLoader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch))\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dominoes\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dominoes\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dominoes\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dominoes\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dominoes\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dominoes\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:171\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dominoes\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dominoes\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [10] at entry 0 and [5] at entry 1"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dhLoader))\n",
    "print(len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff39ac3-9448-43b0-b8fe-6dd89bedb024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649b5964-a579-4cf3-a83f-6a8bbd4daae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e1de8f-7f09-4a59-a5b5-4b940018e285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class dominoeValueDataset(Dataset):\n",
    "    def __init__(self, highestDominoe, min_len=5, max_len=20, num_samples=10000):\n",
    "        self.min_len = min_len\n",
    "        self.max_len = max_len\n",
    "        self.num_samples = num_samples\n",
    "        self.dominoes = df.listDominoes(highestDominoe)\n",
    "        self.numDominoes = len(self.dominoes)\n",
    "        self.dominoeValue = np.sum(self.dominoes,axis=1)\n",
    "        self.hands = [np.random.randint(0, self.numDominoes, length) for \\\n",
    "                          length in np.random.randint(self.min_len, self.max_len, self.num_samples)]\n",
    "        self.targets = [sorted(range(len(chand)), key=lambda i: self.dominoeValue[chand][i]) for chand in self.hands]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        cLength = len(self.targets[index])\n",
    "        cDominoes = self.hands[index]\n",
    "        cTarget = self.targets[index]\n",
    "        row_col_index = list(zip(*[(i,d) for i,d in enumerate(cDominoes)]))\n",
    "        i = torch.LongTensor(row_col_index)\n",
    "        v = torch.FloatTensor([1]*cLength)\n",
    "        cData = torch.sparse.FloatTensor(i,v,torch.Size([cLength, self.numDominoes]))\n",
    "        return cData, cLength, cTarget\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.hands)\n",
    "\n",
    "def sparse_seq_collate_fn(batch):\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    sorted_seqs, sorted_lengths, sorted_labels = zip(*sorted(batch, key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    padded_seqs = [seq.resize_as_(sorted_seqs[0]) for seq in sorted_seqs]\n",
    "\n",
    "    # (Sparse) batch_size X max_seq_len X input_dim\n",
    "    seq_tensor = torch.stack(padded_seqs)\n",
    "\n",
    "    # batch_size\n",
    "    length_tensor = torch.LongTensor(sorted_lengths)\n",
    "\n",
    "    padded_labels = list(zip(*(itertools.zip_longest(*sorted_labels, fillvalue=-1))))\n",
    "\n",
    "    # batch_size X max_seq_len (-1 padding)\n",
    "    label_tensor = torch.LongTensor(padded_labels).view(batch_size, -1)\n",
    "\n",
    "    # TODO: Currently, PyTorch DataLoader with num_workers >= 1 (multiprocessing) does not support Sparse Tensor\n",
    "    # TODO: Meanwhile, use a dense tensor when num_workers >= 1.\n",
    "    seq_tensor = seq_tensor.to_dense()\n",
    "\n",
    "    return seq_tensor, length_tensor, label_tensor\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def masked_accuracy(output, target, mask):\n",
    "    \"\"\"Computes a batch accuracy with a mask (for padded sequences) \"\"\"\n",
    "    with torch.no_grad():\n",
    "        masked_output = torch.masked_select(output, mask)\n",
    "        masked_target = torch.masked_select(target, mask)\n",
    "        accuracy = masked_output.eq(masked_target).float().mean()\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a42401b-f0a3-42fa-add8-69fe69980267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 1: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 2: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 3: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 4: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 5: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 6: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 7: Test\tLoss: 2.551005\tAccuracy: 0.083292\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mupdate(loss\u001b[38;5;241m.\u001b[39mitem(), seq\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     36\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m---> 37\u001b[0m     train_accuracy\u001b[38;5;241m.\u001b[39mupdate(masked_accuracy(argmax_pointer, target, mask)\u001b[38;5;241m.\u001b[39mitem(), mask\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# if batch_idx % 20 == 0:\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m#     print('Epoch {}: Train [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {:.6f}'\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m#           .format(epoch, batch_idx * len(seq), len(train_loader.dataset),\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m#                   100. * batch_idx / len(train_loader), train_loss.avg, train_accuracy.avg))\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Test\u001b[39;00m\n\u001b[0;32m     45\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[4], line 72\u001b[0m, in \u001b[0;36mmasked_accuracy\u001b[1;34m(output, target, mask)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes a batch accuracy with a mask (for padded sequences) \"\"\"\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 72\u001b[0m     masked_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(output, mask)\n\u001b[0;32m     73\u001b[0m     masked_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(target, mask)\n\u001b[0;32m     74\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m masked_output\u001b[38;5;241m.\u001b[39meq(masked_target)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dvTrainSet = dominoeValueDataset(9,num_samples=10000)\n",
    "dvTestSet = dominoeValueDataset(9,num_samples=1000)\n",
    "\n",
    "dvTrainLoader = DataLoader(dataset=dvTrainSet, batch_size=64, shuffle=False, num_workers=0, collate_fn=sparse_seq_collate_fn)\n",
    "dvTestLoader = DataLoader(dataset=dvTestSet, batch_size=64, shuffle=False, num_workers=0, collate_fn=sparse_seq_collate_fn)\n",
    "\n",
    "cudnn.benchmark = True if device=='cuda' else False\n",
    "\n",
    "train_loss = AverageMeter()\n",
    "train_accuracy = AverageMeter()\n",
    "test_loss = AverageMeter()\n",
    "test_accuracy = AverageMeter()\n",
    "\n",
    "net = pn.PointerNet(input_dim=dvDataset.numDominoes, embedding_dim=512, hidden_size=512).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "numEpochs = 1000\n",
    "for epoch in range(numEpochs):\n",
    "    # Train\n",
    "    net.train()\n",
    "    for batch_idx, (seq, length, target) in enumerate(dvLoader):\n",
    "        seq, length, target = seq.to(device), length.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        log_pointer_score, argmax_pointer, mask = net(seq, length)\n",
    "        \n",
    "        unrolled = log_pointer_score.view(-1, log_pointer_score.size(-1))\n",
    "        loss = F.nll_loss(unrolled, target.view(-1), ignore_index=-1)\n",
    "        assert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.update(loss.item(), seq.size(0))\n",
    "\n",
    "        mask = mask[:, 0, :]\n",
    "        train_accuracy.update(masked_accuracy(argmax_pointer, target, mask).item(), mask.int().sum().item())\n",
    "\n",
    "    # Test\n",
    "    net.eval()\n",
    "    for seq, length, target in dvLoader:\n",
    "        seq, length, target = seq.to(device), length.to(device), target.to(device)\n",
    "\n",
    "        log_pointer_score, argmax_pointer, mask = net(seq, length)\n",
    "        unrolled = log_pointer_score.view(-1, log_pointer_score.size(-1))\n",
    "        loss = F.nll_loss(unrolled, target.view(-1), ignore_index=-1)\n",
    "        assert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
    "\n",
    "        test_loss.update(loss.item(), seq.size(0))\n",
    "\n",
    "        mask = mask[:, 0, :]\n",
    "        test_accuracy.update(masked_accuracy(argmax_pointer, target, mask).item(), mask.int().sum().item())\n",
    "    print('Epoch {}: Test\\tLoss: {:.6f}\\tAccuracy: {:.6f}'.format(epoch, test_loss.avg, test_accuracy.avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f034e-94e4-4c4f-a39c-e17da554193d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cb232-0ab4-44f5-81e8-01bb24755027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d89ddb-03bb-4a39-a731-27fbbe741b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d5856-44fe-4702-aa9d-6ec925844bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    # Train\n",
    "    net.train()\n",
    "    for batch_idx, (seq, length, target) in enumerate(train_loader):\n",
    "        seq, length, target = seq.to(device), length.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        log_pointer_score, argmax_pointer, mask = net(seq, length)\n",
    "        \n",
    "        raise ValueError('hi')\n",
    "        \n",
    "        unrolled = log_pointer_score.view(-1, log_pointer_score.size(-1))\n",
    "        loss = F.nll_loss(unrolled, target.view(-1), ignore_index=-1)\n",
    "        assert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.update(loss.item(), seq.size(0))\n",
    "\n",
    "        mask = mask[:, 0, :]\n",
    "        train_accuracy.update(masked_accuracy(argmax_pointer, target, mask).item(), mask.int().sum().item())\n",
    "\n",
    "        # if batch_idx % 20 == 0:\n",
    "        #     print('Epoch {}: Train [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {:.6f}'\n",
    "        #           .format(epoch, batch_idx * len(seq), len(train_loader.dataset),\n",
    "        #                   100. * batch_idx / len(train_loader), train_loss.avg, train_accuracy.avg))\n",
    "\n",
    "    # Test\n",
    "    net.eval()\n",
    "    for seq, length, target in test_loader:\n",
    "        seq, length, target = seq.to(device), length.to(device), target.to(device)\n",
    "\n",
    "        log_pointer_score, argmax_pointer, mask = net(seq, length)\n",
    "        unrolled = log_pointer_score.view(-1, log_pointer_score.size(-1))\n",
    "        loss = F.nll_loss(unrolled, target.view(-1), ignore_index=-1)\n",
    "        assert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
    "\n",
    "        test_loss.update(loss.item(), seq.size(0))\n",
    "\n",
    "        mask = mask[:, 0, :]\n",
    "        test_accuracy.update(masked_accuracy(argmax_pointer, target, mask).item(), mask.int().sum().item())\n",
    "    print('Epoch {}: Test\\tLoss: {:.6f}\\tAccuracy: {:.6f}'.format(epoch, test_loss.avg, test_accuracy.avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5655e2bb-8ed4-4ced-93bf-8c6248cd7e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f13d80-e102-42a7-b443-2f7b5a43482d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92141967-0bac-4eb4-8af9-ed8e7a5cf148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17122dc-6d02-4b98-b4b2-d2b59babf3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee668af4-fc14-42b8-a1ea-505a1f2b26dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e27c34-41e8-432c-a1ac-2b1125ad45a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b498f-4b35-4ced-8166-ff6dbcdc522e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e407a-c737-4707-b290-76c6bc159648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c47aae7-e786-49b1-bbb8-5c9061168755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cd50b-445c-4a56-bf06-ce48982e3e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4077c5-bc35-495a-946a-ad0911f8095a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb4cd8-f00e-495a-8091-740c325b3c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4ae70-a39e-4fc4-aa05-de4066920671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d15d87-e26e-4aad-8a0d-0c75ab6c7995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82eb82-4255-4606-a982-0c2b1f13230b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b5b8e-4c25-4a1b-bcb8-ae597a6275f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b30c8-9ed6-49f0-b684-2fd51ae395b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub Task 2: Order dominoes with a transformer -> pointer network\n",
    "\n",
    "\n",
    "# 1. embed dominoes (can be a variable number, but in each batch should be the same(?))\n",
    "# 2. use a pointer network to produce the output until the last dominoe is used\n",
    "\n",
    "class pointerNetIndex(nn.Module):\n",
    "    def __init__(self, highestDominoe, embedding_dim, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.highestDominoe = highestDominoe\n",
    "        self.dominoes = df.listDominoes(self.highestDominoe)\n",
    "        self.numDominoes = len(self.dominoes)\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        # Start with an embedding layer\n",
    "        self.embedding = nn.Embedding(self.numDominoes, self.embedding_dim)\n",
    "        self.encodedTransform = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        self.decodedTransform = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        self.valueTransform = nn.Linear(self.embedding_dim, 1)\n",
    "\n",
    "        self.pointerNet = nn.GRUCell(input_size, hidden_size, bias=True, device=None, dtype=None\n",
    "\n",
    "        # Inherited from public repository (will test later) \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        embedded = self.embedding(x) # (batch, sequenceLength, embeddingSize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if self.batch_first:\n",
    "            batch_size = input_seq.size(0)\n",
    "            max_seq_len = input_seq.size(1)\n",
    "        else:\n",
    "            batch_size = input_seq.size(1)\n",
    "            max_seq_len = input_seq.size(0)\n",
    "\n",
    "        # Embedding\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # (batch_size, max_seq_len, embedding_dim)\n",
    "\n",
    "        # encoder_output => (batch_size, max_seq_len, hidden_size) if batch_first else (max_seq_len, batch_size, hidden_size)\n",
    "        # hidden_size is usually set same as embedding size\n",
    "        # encoder_hidden => (num_layers * num_directions, batch_size, hidden_size) for each of h_n and c_n\n",
    "        encoder_outputs, encoder_hidden = self.encoder(embedded, input_lengths)\n",
    "\n",
    "        encoder_h_n, encoder_c_n = encoder_hidden\n",
    "        encoder_h_n = encoder_h_n.view(self.num_layers, self.num_directions, batch_size, self.hidden_size)\n",
    "        encoder_c_n = encoder_c_n.view(self.num_layers, self.num_directions, batch_size, self.hidden_size)\n",
    "\n",
    "        # Lets use zeros as an intial input for sorting example\n",
    "        decoder_input = encoder_outputs.new_zeros(torch.Size((batch_size, self.hidden_size)))\n",
    "        decoder_hidden = (encoder_h_n[-1, 0, :, :].squeeze(), encoder_c_n[-1, 0, :, :].squeeze())\n",
    "\n",
    "        range_tensor = torch.arange(max_seq_len, device=input_lengths.device, dtype=input_lengths.dtype).expand(batch_size, max_seq_len, max_seq_len)\n",
    "        each_len_tensor = input_lengths.view(-1, 1, 1).expand(batch_size, max_seq_len, max_seq_len)\n",
    "\n",
    "        row_mask_tensor = (range_tensor < each_len_tensor)\n",
    "        col_mask_tensor = row_mask_tensor.transpose(1, 2)\n",
    "        mask_tensor = row_mask_tensor * col_mask_tensor\n",
    "\n",
    "        pointer_log_scores = []\n",
    "        pointer_argmaxs = []\n",
    "\n",
    "        for i in range(max_seq_len):\n",
    "            # We will simply mask out when calculating attention or max (and loss later)\n",
    "            # not all input and hiddens, just for simplicity\n",
    "            sub_mask = mask_tensor[:, i, :].float()\n",
    "\n",
    "            # h, c: (batch_size, hidden_size)\n",
    "            h_i, c_i = self.decoding_rnn(decoder_input, decoder_hidden)\n",
    "\n",
    "            # next hidden\n",
    "            decoder_hidden = (h_i, c_i)\n",
    "\n",
    "            # Get a pointer distribution over the encoder outputs using attention\n",
    "            # (batch_size, max_seq_len)\n",
    "            log_pointer_score = self.attn(h_i, encoder_outputs, sub_mask)\n",
    "            pointer_log_scores.append(log_pointer_score)\n",
    "\n",
    "            # Get the indices of maximum pointer\n",
    "            _, masked_argmax = masked_max(log_pointer_score, sub_mask, dim=1, keepdim=True)\n",
    "\n",
    "            pointer_argmaxs.append(masked_argmax)\n",
    "            index_tensor = masked_argmax.unsqueeze(-1).expand(batch_size, 1, self.hidden_size)\n",
    "\n",
    "            # (batch_size, hidden_size)\n",
    "            decoder_input = torch.gather(encoder_outputs, dim=1, index=index_tensor).squeeze(1)\n",
    "\n",
    "        pointer_log_scores = torch.stack(pointer_log_scores, 1)\n",
    "        pointer_argmaxs = torch.cat(pointer_argmaxs, 1)\n",
    "\n",
    "        return pointer_log_scores, pointer_argmaxs, mask_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b94147-bfbe-4a6a-a469-3aea7155a5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e0c35-f2ae-4429-af32-5123a5849c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab27e7-615b-4249-95d3-35ccd26325f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac61c2-1a30-43db-bb0f-16ab2127c19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5d791-cc9b-47fd-9d16-716109795350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a596c-44ec-4800-83cf-30df2c434b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606cf08-22aa-4e76-a26e-eb2a01d9bde2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e53ef6d-79e8-462f-8418-97235c038d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbfc990-2ea1-422f-bbc0-e7e1009e04a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a06533-58f5-4f38-a39f-ec30c0c8b714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82066549-813d-474a-b34b-d99ed0c780fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
