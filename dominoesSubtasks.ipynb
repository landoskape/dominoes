{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc1fa0d-ae36-46df-aa4e-6c838e35dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is used for developing networks for subtasks of the main one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ed9ab7-7d09-4a29-9dcb-c76b3d0dc4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from copy import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dominoesGameplay as dg\n",
    "import dominoesAgents as da\n",
    "import dominoesNetworks as dn\n",
    "import dominoesFunctions as df\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import subtasks\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12db2617-cd62-4ad4-9c9a-f83224d9635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sub Task 1: Train a network to predict self-hand value and other hand value based on the tokens in the hand\n",
    "# outputs = subtasks.subTask1()\n",
    "# net, testOutput, testTarget, testLoss, trainingLoss, printResults = outputs\n",
    "# printResults(df.listDominoes(12), trainingLoss, testOutput, testTarget, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1da0b4-c635-4786-a1aa-8111ca4ec73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a21c22-8c73-4b03-9d2b-cbbdb63bcaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37746d0b-c68d-44f2-8a37-724c4c3daf54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pointerNetwork as pn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e1de8f-7f09-4a59-a5b5-4b940018e285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class dominoeValueDataset(Dataset):\n",
    "    def __init__(self, highestDominoe, min_len=5, max_len=20, num_samples=10000):\n",
    "        self.min_len = min_len\n",
    "        self.max_len = max_len\n",
    "        self.num_samples = num_samples\n",
    "        self.dominoes = df.listDominoes(highestDominoe)\n",
    "        self.numDominoes = len(self.dominoes)\n",
    "        self.dominoeValue = np.sum(self.dominoes,axis=1)\n",
    "        self.hands = [np.random.randint(0, self.numDominoes, length) for \\\n",
    "                          length in np.random.randint(self.min_len, self.max_len, self.num_samples)]\n",
    "        self.targets = [sorted(range(len(chand)), key=lambda i: self.dominoeValue[chand][i]) for chand in self.hands]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        cLength = len(self.targets[index])\n",
    "        cDominoes = self.hands[index]\n",
    "        cTarget = self.targets[index]\n",
    "        row_col_index = list(zip(*[(i,d) for i,d in enumerate(cDominoes)]))\n",
    "        i = torch.LongTensor(row_col_index)\n",
    "        v = torch.FloatTensor([1]*cLength)\n",
    "        cData = torch.sparse.FloatTensor(i,v,torch.Size([cLength, self.numDominoes]))\n",
    "        return cData, cLength, cTarget\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.hands)\n",
    "\n",
    "def sparse_seq_collate_fn(batch):\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    sorted_seqs, sorted_lengths, sorted_labels = zip(*sorted(batch, key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    padded_seqs = [seq.resize_as_(sorted_seqs[0]) for seq in sorted_seqs]\n",
    "\n",
    "    # (Sparse) batch_size X max_seq_len X input_dim\n",
    "    seq_tensor = torch.stack(padded_seqs)\n",
    "\n",
    "    # batch_size\n",
    "    length_tensor = torch.LongTensor(sorted_lengths)\n",
    "\n",
    "    padded_labels = list(zip(*(itertools.zip_longest(*sorted_labels, fillvalue=-1))))\n",
    "\n",
    "    # batch_size X max_seq_len (-1 padding)\n",
    "    label_tensor = torch.LongTensor(padded_labels).view(batch_size, -1)\n",
    "\n",
    "    # TODO: Currently, PyTorch DataLoader with num_workers >= 1 (multiprocessing) does not support Sparse Tensor\n",
    "    # TODO: Meanwhile, use a dense tensor when num_workers >= 1.\n",
    "    seq_tensor = seq_tensor.to_dense()\n",
    "\n",
    "    return seq_tensor, length_tensor, label_tensor\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def masked_accuracy(output, target, mask):\n",
    "    \"\"\"Computes a batch accuracy with a mask (for padded sequences) \"\"\"\n",
    "    with torch.no_grad():\n",
    "        masked_output = torch.masked_select(output, mask)\n",
    "        masked_target = torch.masked_select(target, mask)\n",
    "        accuracy = masked_output.eq(masked_target).float().mean()\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a42401b-f0a3-42fa-add8-69fe69980267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 1: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 2: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 3: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 4: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 5: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 6: Test\tLoss: 2.551005\tAccuracy: 0.083292\n",
      "Epoch 7: Test\tLoss: 2.551005\tAccuracy: 0.083292\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mupdate(loss\u001b[38;5;241m.\u001b[39mitem(), seq\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     36\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m---> 37\u001b[0m     train_accuracy\u001b[38;5;241m.\u001b[39mupdate(masked_accuracy(argmax_pointer, target, mask)\u001b[38;5;241m.\u001b[39mitem(), mask\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# if batch_idx % 20 == 0:\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m#     print('Epoch {}: Train [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {:.6f}'\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m#           .format(epoch, batch_idx * len(seq), len(train_loader.dataset),\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m#                   100. * batch_idx / len(train_loader), train_loss.avg, train_accuracy.avg))\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Test\u001b[39;00m\n\u001b[0;32m     45\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[4], line 72\u001b[0m, in \u001b[0;36mmasked_accuracy\u001b[1;34m(output, target, mask)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes a batch accuracy with a mask (for padded sequences) \"\"\"\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 72\u001b[0m     masked_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(output, mask)\n\u001b[0;32m     73\u001b[0m     masked_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(target, mask)\n\u001b[0;32m     74\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m masked_output\u001b[38;5;241m.\u001b[39meq(masked_target)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dvTrainSet = dominoeValueDataset(9,num_samples=10000)\n",
    "dvTestSet = dominoeValueDataset(9,num_samples=1000)\n",
    "\n",
    "dvTrainLoader = DataLoader(dataset=dvTrainSet, batch_size=64, shuffle=False, num_workers=0, collate_fn=sparse_seq_collate_fn)\n",
    "dvTestLoader = DataLoader(dataset=dvTestSet, batch_size=64, shuffle=False, num_workers=0, collate_fn=sparse_seq_collate_fn)\n",
    "\n",
    "cudnn.benchmark = True if device=='cuda' else False\n",
    "\n",
    "train_loss = AverageMeter()\n",
    "train_accuracy = AverageMeter()\n",
    "test_loss = AverageMeter()\n",
    "test_accuracy = AverageMeter()\n",
    "\n",
    "net = pn.PointerNet(input_dim=dvDataset.numDominoes, embedding_dim=512, hidden_size=512).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "numEpochs = 1000\n",
    "for epoch in range(numEpochs):\n",
    "    # Train\n",
    "    net.train()\n",
    "    for batch_idx, (seq, length, target) in enumerate(dvLoader):\n",
    "        seq, length, target = seq.to(device), length.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        log_pointer_score, argmax_pointer, mask = net(seq, length)\n",
    "        \n",
    "        unrolled = log_pointer_score.view(-1, log_pointer_score.size(-1))\n",
    "        loss = F.nll_loss(unrolled, target.view(-1), ignore_index=-1)\n",
    "        assert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.update(loss.item(), seq.size(0))\n",
    "\n",
    "        mask = mask[:, 0, :]\n",
    "        train_accuracy.update(masked_accuracy(argmax_pointer, target, mask).item(), mask.int().sum().item())\n",
    "\n",
    "    # Test\n",
    "    net.eval()\n",
    "    for seq, length, target in dvLoader:\n",
    "        seq, length, target = seq.to(device), length.to(device), target.to(device)\n",
    "\n",
    "        log_pointer_score, argmax_pointer, mask = net(seq, length)\n",
    "        unrolled = log_pointer_score.view(-1, log_pointer_score.size(-1))\n",
    "        loss = F.nll_loss(unrolled, target.view(-1), ignore_index=-1)\n",
    "        assert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
    "\n",
    "        test_loss.update(loss.item(), seq.size(0))\n",
    "\n",
    "        mask = mask[:, 0, :]\n",
    "        test_accuracy.update(masked_accuracy(argmax_pointer, target, mask).item(), mask.int().sum().item())\n",
    "    print('Epoch {}: Test\\tLoss: {:.6f}\\tAccuracy: {:.6f}'.format(epoch, test_loss.avg, test_accuracy.avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f034e-94e4-4c4f-a39c-e17da554193d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cb232-0ab4-44f5-81e8-01bb24755027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d89ddb-03bb-4a39-a731-27fbbe741b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d5856-44fe-4702-aa9d-6ec925844bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    # Train\n",
    "    net.train()\n",
    "    for batch_idx, (seq, length, target) in enumerate(train_loader):\n",
    "        seq, length, target = seq.to(device), length.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        log_pointer_score, argmax_pointer, mask = net(seq, length)\n",
    "        \n",
    "        raise ValueError('hi')\n",
    "        \n",
    "        unrolled = log_pointer_score.view(-1, log_pointer_score.size(-1))\n",
    "        loss = F.nll_loss(unrolled, target.view(-1), ignore_index=-1)\n",
    "        assert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.update(loss.item(), seq.size(0))\n",
    "\n",
    "        mask = mask[:, 0, :]\n",
    "        train_accuracy.update(masked_accuracy(argmax_pointer, target, mask).item(), mask.int().sum().item())\n",
    "\n",
    "        # if batch_idx % 20 == 0:\n",
    "        #     print('Epoch {}: Train [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {:.6f}'\n",
    "        #           .format(epoch, batch_idx * len(seq), len(train_loader.dataset),\n",
    "        #                   100. * batch_idx / len(train_loader), train_loss.avg, train_accuracy.avg))\n",
    "\n",
    "    # Test\n",
    "    net.eval()\n",
    "    for seq, length, target in test_loader:\n",
    "        seq, length, target = seq.to(device), length.to(device), target.to(device)\n",
    "\n",
    "        log_pointer_score, argmax_pointer, mask = net(seq, length)\n",
    "        unrolled = log_pointer_score.view(-1, log_pointer_score.size(-1))\n",
    "        loss = F.nll_loss(unrolled, target.view(-1), ignore_index=-1)\n",
    "        assert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
    "\n",
    "        test_loss.update(loss.item(), seq.size(0))\n",
    "\n",
    "        mask = mask[:, 0, :]\n",
    "        test_accuracy.update(masked_accuracy(argmax_pointer, target, mask).item(), mask.int().sum().item())\n",
    "    print('Epoch {}: Test\\tLoss: {:.6f}\\tAccuracy: {:.6f}'.format(epoch, test_loss.avg, test_accuracy.avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5655e2bb-8ed4-4ced-93bf-8c6248cd7e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f13d80-e102-42a7-b443-2f7b5a43482d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92141967-0bac-4eb4-8af9-ed8e7a5cf148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17122dc-6d02-4b98-b4b2-d2b59babf3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee668af4-fc14-42b8-a1ea-505a1f2b26dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e27c34-41e8-432c-a1ac-2b1125ad45a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b498f-4b35-4ced-8166-ff6dbcdc522e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e407a-c737-4707-b290-76c6bc159648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c47aae7-e786-49b1-bbb8-5c9061168755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cd50b-445c-4a56-bf06-ce48982e3e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4077c5-bc35-495a-946a-ad0911f8095a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb4cd8-f00e-495a-8091-740c325b3c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4ae70-a39e-4fc4-aa05-de4066920671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d15d87-e26e-4aad-8a0d-0c75ab6c7995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82eb82-4255-4606-a982-0c2b1f13230b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b5b8e-4c25-4a1b-bcb8-ae597a6275f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b30c8-9ed6-49f0-b684-2fd51ae395b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub Task 2: Order dominoes with a transformer -> pointer network\n",
    "\n",
    "\n",
    "# 1. embed dominoes (can be a variable number, but in each batch should be the same(?))\n",
    "# 2. use a pointer network to produce the output until the last dominoe is used\n",
    "\n",
    "class pointerNetIndex(nn.Module):\n",
    "    def __init__(self, highestDominoe, embedding_dim, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.highestDominoe = highestDominoe\n",
    "        self.dominoes = df.listDominoes(self.highestDominoe)\n",
    "        self.numDominoes = len(self.dominoes)\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        # Start with an embedding layer\n",
    "        self.embedding = nn.Embedding(self.numDominoes, self.embedding_dim)\n",
    "        self.encodedTransform = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        self.decodedTransform = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        self.valueTransform = nn.Linear(self.embedding_dim, 1)\n",
    "\n",
    "        self.pointerNet = nn.GRUCell(input_size, hidden_size, bias=True, device=None, dtype=None\n",
    "\n",
    "        # Inherited from public repository (will test later) \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        embedded = self.embedding(x) # (batch, sequenceLength, embeddingSize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if self.batch_first:\n",
    "            batch_size = input_seq.size(0)\n",
    "            max_seq_len = input_seq.size(1)\n",
    "        else:\n",
    "            batch_size = input_seq.size(1)\n",
    "            max_seq_len = input_seq.size(0)\n",
    "\n",
    "        # Embedding\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # (batch_size, max_seq_len, embedding_dim)\n",
    "\n",
    "        # encoder_output => (batch_size, max_seq_len, hidden_size) if batch_first else (max_seq_len, batch_size, hidden_size)\n",
    "        # hidden_size is usually set same as embedding size\n",
    "        # encoder_hidden => (num_layers * num_directions, batch_size, hidden_size) for each of h_n and c_n\n",
    "        encoder_outputs, encoder_hidden = self.encoder(embedded, input_lengths)\n",
    "\n",
    "        encoder_h_n, encoder_c_n = encoder_hidden\n",
    "        encoder_h_n = encoder_h_n.view(self.num_layers, self.num_directions, batch_size, self.hidden_size)\n",
    "        encoder_c_n = encoder_c_n.view(self.num_layers, self.num_directions, batch_size, self.hidden_size)\n",
    "\n",
    "        # Lets use zeros as an intial input for sorting example\n",
    "        decoder_input = encoder_outputs.new_zeros(torch.Size((batch_size, self.hidden_size)))\n",
    "        decoder_hidden = (encoder_h_n[-1, 0, :, :].squeeze(), encoder_c_n[-1, 0, :, :].squeeze())\n",
    "\n",
    "        range_tensor = torch.arange(max_seq_len, device=input_lengths.device, dtype=input_lengths.dtype).expand(batch_size, max_seq_len, max_seq_len)\n",
    "        each_len_tensor = input_lengths.view(-1, 1, 1).expand(batch_size, max_seq_len, max_seq_len)\n",
    "\n",
    "        row_mask_tensor = (range_tensor < each_len_tensor)\n",
    "        col_mask_tensor = row_mask_tensor.transpose(1, 2)\n",
    "        mask_tensor = row_mask_tensor * col_mask_tensor\n",
    "\n",
    "        pointer_log_scores = []\n",
    "        pointer_argmaxs = []\n",
    "\n",
    "        for i in range(max_seq_len):\n",
    "            # We will simply mask out when calculating attention or max (and loss later)\n",
    "            # not all input and hiddens, just for simplicity\n",
    "            sub_mask = mask_tensor[:, i, :].float()\n",
    "\n",
    "            # h, c: (batch_size, hidden_size)\n",
    "            h_i, c_i = self.decoding_rnn(decoder_input, decoder_hidden)\n",
    "\n",
    "            # next hidden\n",
    "            decoder_hidden = (h_i, c_i)\n",
    "\n",
    "            # Get a pointer distribution over the encoder outputs using attention\n",
    "            # (batch_size, max_seq_len)\n",
    "            log_pointer_score = self.attn(h_i, encoder_outputs, sub_mask)\n",
    "            pointer_log_scores.append(log_pointer_score)\n",
    "\n",
    "            # Get the indices of maximum pointer\n",
    "            _, masked_argmax = masked_max(log_pointer_score, sub_mask, dim=1, keepdim=True)\n",
    "\n",
    "            pointer_argmaxs.append(masked_argmax)\n",
    "            index_tensor = masked_argmax.unsqueeze(-1).expand(batch_size, 1, self.hidden_size)\n",
    "\n",
    "            # (batch_size, hidden_size)\n",
    "            decoder_input = torch.gather(encoder_outputs, dim=1, index=index_tensor).squeeze(1)\n",
    "\n",
    "        pointer_log_scores = torch.stack(pointer_log_scores, 1)\n",
    "        pointer_argmaxs = torch.cat(pointer_argmaxs, 1)\n",
    "\n",
    "        return pointer_log_scores, pointer_argmaxs, mask_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b94147-bfbe-4a6a-a469-3aea7155a5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e0c35-f2ae-4429-af32-5123a5849c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab27e7-615b-4249-95d3-35ccd26325f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac61c2-1a30-43db-bb0f-16ab2127c19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5d791-cc9b-47fd-9d16-716109795350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a596c-44ec-4800-83cf-30df2c434b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606cf08-22aa-4e76-a26e-eb2a01d9bde2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e53ef6d-79e8-462f-8418-97235c038d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbfc990-2ea1-422f-bbc0-e7e1009e04a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a06533-58f5-4f38-a39f-ec30c0c8b714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82066549-813d-474a-b34b-d99ed0c780fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
